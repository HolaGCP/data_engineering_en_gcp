{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Accediendo a Bigquery con Spark"}, {"cell_type": "markdown", "metadata": {}, "source": "### Crea un cluster de Dataproc con Jupyter\n\nEste notebook esta dise\u00f1ado para ser ejecutado en Google Cloud Dataproc.\nSiga este tutorial para crear el cl\u00faster de Dataproc.\n\n* [Tutorial - Instalar y ejecutar un notebook de jupyter en un cluster de Dataproc](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Python 3 Kernel\n\nUse un kernel de Python 3 (no PySpark) para permitirle configurar SparkSession en el notebook e incluir el [conector de spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) requerido para usar el [API de Bigquery Storage](https://cloud.google.com/bigquery/docs/reference/storage)."}, {"cell_type": "markdown", "metadata": {}, "source": "### Create Spark Session"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n  .appName('1.1. BigQuery Storage & Spark DataFrames - Python')\\\n  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n  .getOrCreate()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Habilita repl.eagerEval\n\nEsto generar\u00e1 los resultados de DataFrames en cada paso sin la nueva necesidad de mostrar `df.show ()` y tambi\u00e9n mejora el formato de la salida"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "if hasattr(__builtins__,'__IPYTHON__'):\n    spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Lea tabla de BigQuery en Spark DataFrame\n\nUsa `filter()` para consultar datos de una tabla particionada."}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- datehour: timestamp (nullable = true)\n |-- wiki: string (nullable = true)\n |-- title: string (nullable = true)\n |-- views: long (nullable = true)\n\n"}], "source": "table = \"bigquery-public-data.wikipedia.pageviews_2022\"\ndf_wiki_pageviews = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table) \\\n  .option(\"filter\", \"datehour >= '2022-10-01' AND datehour < '2022-10-02'\") \\\n  .load()\n\ndf_wiki_pageviews.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "Seleccione las columnas requeridas y aplique un filtro usando `where()` que es un alias para `filter()` y luego almacene en cach\u00e9 la tabla"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>datehour</th><th>title</th><th>wiki</th><th>views</th></tr>\n<tr><td>2022-10-01 18:00:00</td><td>Especial:Buscar</td><td>es</td><td>2323</td></tr>\n<tr><td>2022-10-01 01:00:00</td><td>Especial:Buscar</td><td>es</td><td>1823</td></tr>\n<tr><td>2022-10-01 16:00:00</td><td>Especial:Buscar</td><td>es</td><td>2084</td></tr>\n<tr><td>2022-10-01 21:00:00</td><td>Especial:Buscar</td><td>es</td><td>2084</td></tr>\n<tr><td>2022-10-01 02:00:00</td><td>Especial:Buscar</td><td>es</td><td>1595</td></tr>\n<tr><td>2022-10-01 20:00:00</td><td>Especial:Buscar</td><td>es</td><td>2111</td></tr>\n<tr><td>2022-10-01 12:00:00</td><td>Especial:Buscar</td><td>es</td><td>1099</td></tr>\n<tr><td>2022-10-01 03:00:00</td><td>Especial:Buscar</td><td>es</td><td>1378</td></tr>\n<tr><td>2022-10-01 19:00:00</td><td>Especial:Buscar</td><td>es</td><td>2445</td></tr>\n<tr><td>2022-10-01 13:00:00</td><td>Especial:Buscar</td><td>es</td><td>1167</td></tr>\n<tr><td>2022-10-01 11:00:00</td><td>Especial:Buscar</td><td>es</td><td>1180</td></tr>\n<tr><td>2022-10-01 15:00:00</td><td>Especial:Buscar</td><td>es</td><td>1952</td></tr>\n<tr><td>2022-10-01 17:00:00</td><td>Especial:Buscar</td><td>es</td><td>2264</td></tr>\n<tr><td>2022-10-01 04:00:00</td><td>Especial:Buscar</td><td>es</td><td>1257</td></tr>\n<tr><td>2022-10-01 00:00:00</td><td>Especial:Buscar</td><td>es</td><td>2032</td></tr>\n<tr><td>2022-10-01 05:00:00</td><td>Especial:Buscar</td><td>es</td><td>1019</td></tr>\n<tr><td>2022-10-01 14:00:00</td><td>Especial:Buscar</td><td>es</td><td>1279</td></tr>\n<tr><td>2022-10-01 23:00:00</td><td>Merche</td><td>es.m</td><td>1028</td></tr>\n<tr><td>2022-10-01 22:00:00</td><td>Lorenzo_Faravelli</td><td>es.m</td><td>3847</td></tr>\n<tr><td>2022-10-01 22:00:00</td><td>Operaci\u00f3n_Antropoide</td><td>es.m</td><td>3094</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+-------------------+--------------------+----+-----+\n|           datehour|               title|wiki|views|\n+-------------------+--------------------+----+-----+\n|2022-10-01 18:00:00|     Especial:Buscar|  es| 2323|\n|2022-10-01 01:00:00|     Especial:Buscar|  es| 1823|\n|2022-10-01 16:00:00|     Especial:Buscar|  es| 2084|\n|2022-10-01 21:00:00|     Especial:Buscar|  es| 2084|\n|2022-10-01 02:00:00|     Especial:Buscar|  es| 1595|\n|2022-10-01 20:00:00|     Especial:Buscar|  es| 2111|\n|2022-10-01 12:00:00|     Especial:Buscar|  es| 1099|\n|2022-10-01 03:00:00|     Especial:Buscar|  es| 1378|\n|2022-10-01 19:00:00|     Especial:Buscar|  es| 2445|\n|2022-10-01 13:00:00|     Especial:Buscar|  es| 1167|\n|2022-10-01 11:00:00|     Especial:Buscar|  es| 1180|\n|2022-10-01 15:00:00|     Especial:Buscar|  es| 1952|\n|2022-10-01 17:00:00|     Especial:Buscar|  es| 2264|\n|2022-10-01 04:00:00|     Especial:Buscar|  es| 1257|\n|2022-10-01 00:00:00|     Especial:Buscar|  es| 2032|\n|2022-10-01 05:00:00|     Especial:Buscar|  es| 1019|\n|2022-10-01 14:00:00|     Especial:Buscar|  es| 1279|\n|2022-10-01 23:00:00|              Merche|es.m| 1028|\n|2022-10-01 22:00:00|   Lorenzo_Faravelli|es.m| 3847|\n|2022-10-01 22:00:00|Operaci\u00f3n_Antropoide|es.m| 3094|\n+-------------------+--------------------+----+-----+\nonly showing top 20 rows"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "df_wiki_es = df_wiki_pageviews \\\n  .select(\"datehour\",\"title\", \"wiki\", \"views\") \\\n  .where(\"views > 1000 AND wiki in ('es', 'es.m')\") \\\n  .cache()\n\ndf_wiki_es"}, {"cell_type": "markdown", "metadata": {}, "source": "Agrupar por t\u00edtulo y ordenar por vistas de p\u00e1gina para ver las p\u00e1ginas principales"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>title</th><th>total_views</th></tr>\n<tr><td>Wikipedia:Portada</td><td>600232</td></tr>\n<tr><td>Jeffrey_Dahmer</td><td>320606</td></tr>\n<tr><td>Marilyn_Monroe</td><td>159669</td></tr>\n<tr><td>Especial:Buscar</td><td>98182</td></tr>\n<tr><td>Cleopatra</td><td>97850</td></tr>\n<tr><td>Isabel_de_Baviera</td><td>55507</td></tr>\n<tr><td>Cleopatra_I_de_Eg...</td><td>36097</td></tr>\n<tr><td>Francisco_Jos\u00e9_I_...</td><td>34798</td></tr>\n<tr><td>Premier_League</td><td>32461</td></tr>\n<tr><td>Evan_Peters</td><td>32440</td></tr>\n<tr><td>Independiente_del...</td><td>26085</td></tr>\n<tr><td>John_Wayne_Gacy</td><td>18110</td></tr>\n<tr><td>\u00c0ngel_Casas</td><td>17192</td></tr>\n<tr><td>Hocus_Pocus_(pel\u00ed...</td><td>15952</td></tr>\n<tr><td>Arthur_Miller</td><td>14808</td></tr>\n<tr><td>Copa_Sudamericana</td><td>13200</td></tr>\n<tr><td>Ana_de_Armas</td><td>11379</td></tr>\n<tr><td>Lautaro_Ariel_D\u00edaz</td><td>10833</td></tr>\n<tr><td>Oscar_Pistorius</td><td>10825</td></tr>\n<tr><td>F\u00fatbol_Club_Barce...</td><td>10107</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+--------------------+-----------+\n|               title|total_views|\n+--------------------+-----------+\n|   Wikipedia:Portada|     600232|\n|      Jeffrey_Dahmer|     320606|\n|      Marilyn_Monroe|     159669|\n|     Especial:Buscar|      98182|\n|           Cleopatra|      97850|\n|   Isabel_de_Baviera|      55507|\n|Cleopatra_I_de_Eg...|      36097|\n|Francisco_Jos\u00e9_I_...|      34798|\n|      Premier_League|      32461|\n|         Evan_Peters|      32440|\n|Independiente_del...|      26085|\n|     John_Wayne_Gacy|      18110|\n|         \u00c0ngel_Casas|      17192|\n|Hocus_Pocus_(pel\u00ed...|      15952|\n|       Arthur_Miller|      14808|\n|   Copa_Sudamericana|      13200|\n|        Ana_de_Armas|      11379|\n|  Lautaro_Ariel_D\u00edaz|      10833|\n|     Oscar_Pistorius|      10825|\n|F\u00fatbol_Club_Barce...|      10107|\n+--------------------+-----------+\nonly showing top 20 rows"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "import pyspark.sql.functions as F\n\ndf_wiki_en_totals = df_wiki_es \\\n.groupBy(\"title\") \\\n.agg(F.sum('views').alias('total_views'))\n\ndf_wiki_en_totals.orderBy('total_views', ascending=False)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Escriba Spark Dataframe to BigQuery table\n\nEscriba el Spark Dataframe en la tabla de BigQuery mediante el conector de almacenamiento de BigQuery. Esto tambi\u00e9n crear\u00e1 la tabla si no existe.\n\nPrimero debemos crear o verificar el bucket y el dataset"}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": "from google.cloud import storage\nclient = storage.Client()\nbucket_name = client.project\ntry:\n    client.get_bucket(bucket_name)\nexcept:\n    client.create_bucket(bucket_name, location=\"us-east1\")\n    print(\"Bucket {} creado\".format(bucket_name))"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Created dataset secret-footing-366022.dataproc\n"}], "source": "from google.cloud import bigquery\n\nbq_client = bigquery.Client()\ndataset_id = \"{}.dataproc\".format(bq_client.project)\ntry:\n    bq_client.get_dataset(dataset_id)\nexcept:\n    dataset = bigquery.Dataset(dataset_id)\n    dataset.location = \"us-east1\"\n    dataset = bq_client.create_dataset(dataset)  # Make an API request.\n    print(\"Dataset {}.{} creado\".format(bq_client.project, dataset.dataset_id))"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# If the table does not exist it will be created when you run the write function\nbq_table = 'wiki_total_pageviews'\n\ndf_wiki_en_totals.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"{}.{}\".format(dataset_id, bq_table)) \\\n  .option(\"temporaryGcsBucket\", bucket_name) \\\n  .mode('overwrite') \\\n  .save()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Usa \"BigQuery magic\" para consultar la tabla\n\nUtilice [BigQuery magic](https://googleapis.dev/python/bigquery/latest/magics.html) para comprobar si los datos se crearon correctamente en BigQuery. Esto ejecutar\u00e1 la consulta SQL en BigQuery y devolver\u00e1 los resultados."}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Query complete after 0.02s: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 522.07query/s]                          \nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  9.52rows/s]\n"}, {"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>total_views</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wikipedia:Portada</td>\n      <td>600232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jeffrey_Dahmer</td>\n      <td>320606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Marilyn_Monroe</td>\n      <td>159669</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Especial:Buscar</td>\n      <td>98182</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cleopatra</td>\n      <td>97850</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Isabel_de_Baviera</td>\n      <td>55507</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Cleopatra_I_de_Egipto</td>\n      <td>36097</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Francisco_Jos\u00e9_I_de_Austria</td>\n      <td>34798</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Premier_League</td>\n      <td>32461</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Evan_Peters</td>\n      <td>32440</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                         title  total_views\n0            Wikipedia:Portada       600232\n1               Jeffrey_Dahmer       320606\n2               Marilyn_Monroe       159669\n3              Especial:Buscar        98182\n4                    Cleopatra        97850\n5            Isabel_de_Baviera        55507\n6        Cleopatra_I_de_Egipto        36097\n7  Francisco_Jos\u00e9_I_de_Austria        34798\n8               Premier_League        32461\n9                  Evan_Peters        32440"}, "execution_count": 28, "metadata": {}, "output_type": "execute_result"}], "source": "%%bigquery\nSELECT title, total_views\nFROM dataproc.wiki_total_pageviews\nORDER BY total_views DESC\nLIMIT 10"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 4}