{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Accediendo a Cloud Storage con Spark"}, {"cell_type": "markdown", "metadata": {}, "source": "### Crea un cluster de Dataproc con Jupyter\n\nEste notebook esta dise\u00f1ado para ser ejecutado en Google Cloud Dataproc.\nSiga este tutorial para crear el cl\u00faster de Dataproc.\n\n* [Tutorial - Instalar y ejecutar un notebook de jupyter en un cluster de Dataproc](https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Python 3 Kernel\n\nUse un kernel de Python 3 (no PySpark) para permitirle configurar SparkSession en el notebook"}, {"cell_type": "markdown", "metadata": {}, "source": "### Create Spark Session"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n22/11/11 23:52:16 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n22/11/11 23:52:16 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n22/11/11 23:52:16 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n22/11/11 23:52:16 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n  .appName('Cloud Storage') \\\n  .getOrCreate()"}, {"cell_type": "markdown", "metadata": {}, "source": "### Habilita repl.eagerEval\n\nEsto generar\u00e1 los resultados de DataFrames en cada paso sin la nueva necesidad de mostrar `df.show ()` y tambi\u00e9n mejora el formato de la salida"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "if hasattr(__builtins__,'__IPYTHON__'):\n    spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Lista los archivos en un bucket de GCS"}, {"cell_type": "markdown", "metadata": {}, "source": "Usando el [sdk de python](https://googleapis.dev/python/storage/latest/client.html) que viene instalado en el cluster de Dataproc. Vamos a usar un dataset p\u00fablico."}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": "[<Blob: solutions-public-assets, time-series-master/GBPUSD_2014_01.csv, 1643821118808732>,\n <Blob: solutions-public-assets, time-series-master/GBPUSD_2014_02.csv, 1643821119500006>,\n <Blob: solutions-public-assets, time-series-master/readme.txt, 1643821238542920>]"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "from google.cloud import storage\n\ngcs_client = storage.Client()\nbucket = gcs_client.bucket('solutions-public-assets')\n\nlist(bucket.list_blobs(prefix='time-series-master/'))"}, {"cell_type": "markdown", "metadata": {}, "source": "### Lee los archivos CSV de GCS hacia un Dataframe de Spark."}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:=============================>                             (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- XYZ: string (nullable = true)\n |-- GBP/USD: string (nullable = true)\n |-- 2014-01-01 00:00:00.000000: string (nullable = true)\n |-- 1.4995: double (nullable = true)\n |-- 1.5005: double (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df1 = spark \\\n  .read \\\n  .option ( \"inferSchema\" , \"true\" ) \\\n  .option ( \"header\" , \"true\" ) \\\n  .csv ( \"gs://solutions-public-assets/time-series-master/GBPUSD_*.csv\" )\n\ndf1.printSchema()"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>XYZ</th><th>GBP/USD</th><th>2014-01-01 00:00:00.000000</th><th>1.4995</th><th>1.5005</th></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.498</td><td>1.499</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+---+-------+--------------------------+------+------+\n|XYZ|GBP/USD|2014-01-01 00:00:00.000000|1.4995|1.5005|\n+---+-------+--------------------------+------+------+\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4988|1.4998|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4993|1.5003|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4989|1.4999|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4998|1.5008|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.5001|1.5011|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4991|1.5001|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4978|1.4988|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4974|1.4984|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4987|1.4997|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n|XYZ|GBP/USD|      2014-01-01 00:00:...|1.4979|1.4989|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4991|1.5001|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4997|1.5007|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4996|1.5006|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4998|1.5008|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4995|1.5005|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4992|1.5002|\n|XYZ|GBP/USD|      2014-01-01 00:01:...|1.4979|1.4989|\n|XYZ|GBP/USD|      2014-01-01 00:01:...| 1.498| 1.499|\n+---+-------+--------------------------+------+------+\nonly showing top 20 rows"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "df1"}, {"cell_type": "markdown", "metadata": {}, "source": "Si no hay un encabezado con los nombres de las columnas, como podemos ver aqu\u00ed con el conjunto de datos, o si el esquema no se infiere correctamente, lea los archivos CSV de GCS y defina el esquema."}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- venue: string (nullable = true)\n |-- currencies: string (nullable = true)\n |-- time_stamp: timestamp (nullable = true)\n |-- bid: double (nullable = true)\n |-- ask: double (nullable = true)\n\n"}], "source": "from pyspark.sql.types import StructType, StructField\nfrom pyspark.sql.types import DoubleType, IntegerType, StringType, TimestampType, DateType\n\nschema = StructType([\n    StructField(\"venue\", StringType()),\n    StructField(\"currencies\", StringType()),\n    StructField(\"time_stamp\", TimestampType()),\n    StructField(\"bid\", DoubleType()),\n    StructField(\"ask\", DoubleType())\n])\n\ndf2 = spark \\\n  .read \\\n  .schema(schema) \\\n  .csv ( \"gs://solutions-public-assets/time-series-master/GBPUSD_*.csv\" )\n\ndf2.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "View the top 20 rows of the spark dataframe"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>venue</th><th>currencies</th><th>time_stamp</th><th>bid</th><th>ask</th></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:00</td><td>1.4995</td><td>1.5005</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+-----+----------+--------------------+------+------+\n|venue|currencies|          time_stamp|   bid|   ask|\n+-----+----------+--------------------+------+------+\n|  XYZ|   GBP/USD| 2014-01-01 00:00:00|1.4995|1.5005|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4988|1.4998|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4993|1.5003|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4989|1.4999|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4998|1.5008|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.5001|1.5011|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4991|1.5001|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4978|1.4988|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4974|1.4984|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4987|1.4997|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4991|1.5001|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4997|1.5007|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4996|1.5006|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4998|1.5008|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4995|1.5005|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4992|1.5002|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4979|1.4989|\n+-----+----------+--------------------+------+------+\nonly showing top 20 rows"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "df2"}, {"cell_type": "markdown", "metadata": {}, "source": "Imprime las dimensiones del Dataframe. N\u00famero de filas y n\u00famero de columnas"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 6:=============================>                             (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "(2436683, 5)\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "print((df2.count(), len(df2.columns)))"}, {"cell_type": "markdown", "metadata": {}, "source": "Agregue la columna de hora y filtre los datos para crear un nuevo dataframe con solo 1 d\u00eda de datos"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>venue</th><th>currencies</th><th>time_stamp</th><th>bid</th><th>ask</th><th>hour</th></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:00</td><td>1.4995</td><td>1.5005</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4988</td><td>1.4998</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4993</td><td>1.5003</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4989</td><td>1.4999</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4998</td><td>1.5008</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.5001</td><td>1.5011</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4991</td><td>1.5001</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4978</td><td>1.4988</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4974</td><td>1.4984</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4987</td><td>1.4997</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:00:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4991</td><td>1.5001</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4997</td><td>1.5007</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4996</td><td>1.5006</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4998</td><td>1.5008</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4995</td><td>1.5005</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4992</td><td>1.5002</td><td>0</td></tr>\n<tr><td>XYZ</td><td>GBP/USD</td><td>2014-01-01 00:01:...</td><td>1.4979</td><td>1.4989</td><td>0</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+-----+----------+--------------------+------+------+----+\n|venue|currencies|          time_stamp|   bid|   ask|hour|\n+-----+----------+--------------------+------+------+----+\n|  XYZ|   GBP/USD| 2014-01-01 00:00:00|1.4995|1.5005|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4988|1.4998|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4993|1.5003|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4989|1.4999|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4998|1.5008|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.5001|1.5011|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4991|1.5001|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4978|1.4988|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4974|1.4984|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4987|1.4997|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:00:...|1.4979|1.4989|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4991|1.5001|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4997|1.5007|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4996|1.5006|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4998|1.5008|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4995|1.5005|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4992|1.5002|   0|\n|  XYZ|   GBP/USD|2014-01-01 00:01:...|1.4979|1.4989|   0|\n+-----+----------+--------------------+------+------+----+\nonly showing top 20 rows"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": "import pyspark.sql.functions as F\n\ndf3 = df2.withColumn(\"hour\", F.hour(F.col(\"time_stamp\"))) \\\n  .filter(df2['time_stamp'] >= F.lit('2014-01-01 00:00:00')) \\\n  .filter(df2['time_stamp'] < F.lit('2014-01-02 00:00:10')).cache()\n\ndf3"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 11:===========================================>              (3 + 1) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "(41390, 6)\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "print((df3.count(), len(df3.columns)))"}, {"cell_type": "markdown", "metadata": {}, "source": "Agrupalo por \"hour\" y ordenalo por \"total_bids\""}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/html": "<table border='1'>\n<tr><th>hour</th><th>total_bids</th></tr>\n<tr><td>12</td><td>4888.966399999975</td></tr>\n<tr><td>13</td><td>4852.239699999989</td></tr>\n<tr><td>14</td><td>4569.660199999988</td></tr>\n<tr><td>15</td><td>4518.744800000002</td></tr>\n<tr><td>8</td><td>2489.1048999999966</td></tr>\n<tr><td>10</td><td>2431.1414000000077</td></tr>\n<tr><td>9</td><td>2424.1796000000018</td></tr>\n<tr><td>18</td><td>2368.89479999999</td></tr>\n<tr><td>19</td><td>2355.5363999999986</td></tr>\n<tr><td>11</td><td>2347.3602999999907</td></tr>\n<tr><td>17</td><td>2300.944100000002</td></tr>\n<tr><td>16</td><td>2295.8520999999996</td></tr>\n<tr><td>4</td><td>1749.3830000000016</td></tr>\n<tr><td>5</td><td>1726.0291000000027</td></tr>\n<tr><td>6</td><td>1662.2480999999957</td></tr>\n<tr><td>7</td><td>1648.9573000000023</td></tr>\n<tr><td>20</td><td>1572.7295999999976</td></tr>\n<tr><td>21</td><td>1558.4258999999997</td></tr>\n<tr><td>23</td><td>1546.2942000000016</td></tr>\n<tr><td>22</td><td>1512.3183999999997</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+----+------------------+\n|hour|        total_bids|\n+----+------------------+\n|  12| 4888.966399999975|\n|  13| 4852.239699999989|\n|  14| 4569.660199999988|\n|  15| 4518.744800000002|\n|   8|2489.1048999999966|\n|  10|2431.1414000000077|\n|   9|2424.1796000000018|\n|  18|  2368.89479999999|\n|  19|2355.5363999999986|\n|  11|2347.3602999999907|\n|  17| 2300.944100000002|\n|  16|2295.8520999999996|\n|   4|1749.3830000000016|\n|   5|1726.0291000000027|\n|   6|1662.2480999999957|\n|   7|1648.9573000000023|\n|  20|1572.7295999999976|\n|  21|1558.4258999999997|\n|  23|1546.2942000000016|\n|  22|1512.3183999999997|\n+----+------------------+\nonly showing top 20 rows"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "import pyspark.sql.functions as F\n\ndf4 = df3 \\\n.groupBy(\"hour\") \\\n.agg(F.sum('bid').alias('total_bids'))\n\ndf4.orderBy('total_bids', ascending=False)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Escriba el Dataframe de Spark en Google Cloud Storage en formato CSV"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "gcs_bucket = gcs_client.project\n\ngcs_filepath = 'gs://{}/currency/hourly_bids.csv'.format(gcs_bucket)\n\ndf4.coalesce(1).write \\\n    .option(\"header\", \"true\") \\\n  .mode('overwrite') \\\n  .csv(gcs_filepath)"}, {"cell_type": "markdown", "metadata": {}, "source": "Lea el archivo CSV en el nuevo DataFrame para comprobar que se guard\u00f3 correctamente"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/html": "<table border='1'>\n<tr><th>hour</th><th>total_bids</th></tr>\n<tr><td>12</td><td>4888.966399999975</td></tr>\n<tr><td>22</td><td>1512.3183999999997</td></tr>\n<tr><td>1</td><td>1040.8376999999998</td></tr>\n<tr><td>13</td><td>4852.239699999989</td></tr>\n<tr><td>6</td><td>1662.2480999999957</td></tr>\n<tr><td>16</td><td>2295.8520999999996</td></tr>\n<tr><td>3</td><td>1032.2795000000003</td></tr>\n<tr><td>20</td><td>1572.7295999999976</td></tr>\n<tr><td>5</td><td>1726.0291000000027</td></tr>\n<tr><td>19</td><td>2355.5363999999986</td></tr>\n<tr><td>15</td><td>4518.744800000002</td></tr>\n<tr><td>9</td><td>2424.1796000000018</td></tr>\n<tr><td>17</td><td>2300.944100000002</td></tr>\n<tr><td>4</td><td>1749.3830000000016</td></tr>\n<tr><td>8</td><td>2489.1048999999966</td></tr>\n<tr><td>23</td><td>1546.2942000000016</td></tr>\n<tr><td>7</td><td>1648.9573000000023</td></tr>\n<tr><td>10</td><td>2431.1414000000077</td></tr>\n<tr><td>21</td><td>1558.4258999999997</td></tr>\n<tr><td>11</td><td>2347.3602999999907</td></tr>\n</table>\nonly showing top 20 rows\n", "text/plain": "+----+------------------+\n|hour|        total_bids|\n+----+------------------+\n|  12| 4888.966399999975|\n|  22|1512.3183999999997|\n|   1|1040.8376999999998|\n|  13| 4852.239699999989|\n|   6|1662.2480999999957|\n|  16|2295.8520999999996|\n|   3|1032.2795000000003|\n|  20|1572.7295999999976|\n|   5|1726.0291000000027|\n|  19|2355.5363999999986|\n|  15| 4518.744800000002|\n|   9|2424.1796000000018|\n|  17| 2300.944100000002|\n|   4|1749.3830000000016|\n|   8|2489.1048999999966|\n|  23|1546.2942000000016|\n|   7|1648.9573000000023|\n|  10|2431.1414000000077|\n|  21|1558.4258999999997|\n|  11|2347.3602999999907|\n+----+------------------+\nonly showing top 20 rows"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "df5 = spark.read \\\n  .option ( \"inferSchema\" , \"true\" ) \\\n  .option ( \"header\" , \"true\" ) \\\n  .csv(f'gs://{gcs_client.project}/currency/*')\n\ndf5"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}}, "nbformat": 4, "nbformat_minor": 4}